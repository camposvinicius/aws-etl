spark-submit --deploy-mode client --conf spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version=2 --conf spark.speculation=false --conf spark.sql.broadcastTimeout=900 --conf spark.sql.adaptive.enabled=true --conf spark.shuffle.service.enabled=true --conf spark.dynamicAllocation.enabled=true --conf spark.sql.adaptive.coalescePartitions.enabled=true --conf spark.sql.adaptive.coalescePartitions.minPartitionNum=1 --conf spark.sql.adaptive.coalescePartitions.initialPartitionNum=10  --conf spark.sql.adaptive.advisoryPartitionSizeInBytes=134217728 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer --conf spark.dynamicAllocation.minExecutors=5 --conf spark.dynamicAllocation.maxExecutors=30 --conf spark.dynamicAllocation.initialExecutors=10 --conf spark.sql.debug.maxToStringFields=100 --conf spark.sql.join.preferSortMergeJoin=true --py-files k8s/codes/variables.py k8s/codes/csv-to-parquet.py "{\"file\":\"classification\", \"format_source\":\"csv\", \"format_target\":\"parquet\"}"